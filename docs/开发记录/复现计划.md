# 任务与约束复述

## 目标

- 在 PandaSet 上复现 Flux4D 的主要指标（PSNR/SSIM/Depth RMSE/Flow EPE），并输出可视化结果。
- 实现无监督 4D 重建：预测 3D 高斯及其运动，支持任意时间与视角渲染。

## 约束与资源

- 数据集：PandaSet（/home/yr/yr/data/automonous/pandaset），后续可扩展 Waymo。
- 参考代码：GaussianSTORM（/home/yr/yr/code/cv/AutoLabel/SSL/GaussianSTORM_all/GaussianSTORM，环境 storm，环境路径为/home/yr/anaconda3/envs/gaussianstorm）。
- 运行环境路径为/home/yr/anaconda3/envs/gaussianstorm
- 硬件：1×5090 24G，需要控制视图数、分辨率与高斯数量。
  备注：我在24G的5090上是进行调试,可以将batch调小,所以直接和论文中的视图数与分辨率保持一致即可,我最终会在A100上训练.
- 无官方仓库，需按论文与翻译落地实现。
- 代码开发要遵守google python代码开发规范，并且每个类和函数需要有注释，至少要说明输入输出参数说明以及实现的功能和实现方法是什么
- 每个阶段完成后，要用git进行版本管理，方便修改与记录。

# 论文技术拆解

## 任务定义与场景表示

- 输入：多相机 RGB、LiDAR 点云、内外参与时间戳。
- 输出：一组 3D 高斯 g_i = (p_i, s_i, R_i, c_i, α_i) + 速度 v_i + 时间戳 t_i。
- 目标：在连续时间上推进高斯并可微渲染，支持新视角/新时间的 RGB、Depth、Flow。

## 初始化（Lift）

- 从每个 LiDAR 帧 P_k 初始化高斯位置 p_i。
- 缩放 s_i：依据邻域平均距离估计（点密集处更小尺度）。
- 颜色 c_i：将点投影到同步相机图像 I_k 采样。
- 时间戳 t_i：取 LiDAR 帧时间；速度初值 v_i = 0。
- 聚合多帧高斯得到 G_init。
- 论文实现还会在远处球面采样随机点模拟天空/远景，并在 3D 球体内采样随机点增强鲁棒性。

## 预测网络 fθ（稀疏 3D U-Net）

- 采用带稀疏卷积的 3D U-Net 作为 fθ（TorchSparse++）。
- 输入：G_init 与时间戳 T（体素化后形成稀疏张量）。
- 输出：精炼高斯参数 G 与速度 V（逐高斯预测）。
- 多场景联合训练形成隐式先验，自动分解静态/动态。

## 时间推进与渲染

- 线性运动模型：
  p_i(t') = p_i(t_i) + v_i * (t' - t_i)
- 使用 3DGS 可微渲染生成 RGB/Depth。
- 光流在图像平面渲染，用于评估与动态重加权。

## 损失函数（Flux4D-base）

- 总损失：
  L = L_recon + λ_vel L_vel
- 重建损失：
  L_recon = λ_rgb L1(RGB) + λ_SSIM SSIM + λ_depth L1(Depth)
- 速度正则：
  L_vel = (1/M) Σ_i ||v_i||_2
- 论文权重参考：λ_rgb=0.8，λ_SSIM=0.2，λ_depth=0.01，λ_vel=5e-3。

## 迭代优化与运动增强（Flux4D）

- 迭代优化：渲染后对高斯求 3D 梯度，将 (G, grad) 输入 f_φ 进行 1–2 次细化，提升细节一致性。
- 运动增强：引入多项式运动参数化更好拟合加速/转弯等复杂动力学。
- 动态重加权：根据渲染光流对光度损失逐像素加权，强调动态区域。

## 与 GaussianSTORM 的对应与改造

- 可复用：gsplat/3DGS 渲染器、数据管线、多视图采样与训练脚手架。
- 关键改造：
  - 表示层：从 STORM 的 token/特征驱动改为 LiDAR 初始化高斯 + 速度预测。
  - 主干网络：以稀疏 3D U-Net 为主，输出逐高斯更新与速度。
  - 损失：以光度+深度+速度正则为核心，加入动态重加权与迭代 refinement。
  - 训练：多场景联合训练，支持高分辨率多视图输入。

## 对原提示词的修正/补充

- 预测模块主干为稀疏 3D U-Net，而非 Transformer。
- 论文区分 Flux4D-base 与 Flux4D（包含迭代优化与运动增强）。
- 无界场景处理加入随机远景/天空点，这一实现细节需补充。

# 分阶段实现路线图

## 阶段0：环境与基线验证

- 在 storm 环境跑通 GaussianSTORM demo，确认渲染与数据读取链路。
- 核对 PandaSet 时间同步与标定文件可用性。
- 24G 5090 调试保持论文视图数与分辨率，仅通过 batch/梯度累积控显存。

## 阶段1：PandaSet 数据索引与切片

- 生成 `data/metadata/pandaset_full_clips.pkl` 与 `data/metadata/pandaset_tiny_clips.pkl`。我想用Pkl存储数据索引。
- 每条记录包含时间戳、相机/雷达外参、图像/点云路径与可见视图。
- 对齐论文设置：10Hz，1.5s 片段；训练/验证场景拆分与论文规模一致。
- 对于生成的数据索引和pandaset数据本身，以及数据使用方法，要有说明文档，生成一个数据说明文档放在docs/数据处理与说明/数据处理与说明.md中

## 阶段2：LiDAR → 高斯（Lift）实现与门禁

- 实现体素下采样、kNN 平均距离尺度估计、图像投影采色。
- 生成 G_init 并统计高斯数量与尺度分布。
- 可视化门禁：渲染 RGB/Depth 与原图/投影深度对比对齐。

## 阶段3：稀疏 3D U-Net 预测器（Flux4D-base）

- 体素化 G_init，构建稀疏张量输入 3D U-Net。
- 输出逐高斯属性更新与速度。
- tiny clip 过拟合验证：重建 loss 下降、PSNR/SSIM 上升、速度趋稳。

## 阶段4：时间推进与光流渲染

- 实现线性运动推进与多时间步渲染。
- 渲染 RGB/Depth/Flow，检查 flow 方向与相邻帧位移一致性。
- 建立插值/未来帧渲染流程，贴近论文评测设置。

## 阶段5：Flux4D 完整增强

- 加入迭代优化：渲染后获取 3D 梯度，进行二次 refinement。
- 加入动态重加权：由渲染 flow 构造权重图，强化动态区域损失。
- 可选：多项式运动模型，做消融确认收益后再启用。

## 阶段6：全量训练与评测

- PandaSet full 训练，输出 PSNR/SSIM/Depth RMSE/Flow EPE。
- 评测设置对齐论文：输入 {0,2,4,6,8,10}，评估插值与未来帧。
- 生成典型场景 4D 重建视频与新视角对比。

# 模块–文件–函数级 TODO 列表

## 顶层结构设计

```
.
├── configs/                 # 训练/评测配置
├── data/
│   ├── metadata/            # full/tiny clip 索引
│   └── cache/               # Lift 缓存（可选）
├── src/
│   └── flux4d/
│       ├── datasets/        # PandaSet/Waymo 读取与对齐
│       ├── lift/            # LiDAR -> Gaussians
│       ├── render/          # 时间推进 + 3DGS 渲染 + 光流
│       ├── storm/           # 核心模型（复用 GaussianSTORM 思路）
│       ├── losses/          # 光度/速度/动态重加权
│       ├── metrics/         # PSNR/SSIM/Depth/Flow 指标
│       ├── engine/          # 训练与评测循环
│       └── utils/           # 通用工具与数值辅助
├── scripts/
│   ├── preprocess_flux4d.py # 生成 full/tiny 索引
│   ├── train_flux4d.py      # 训练入口
│   └── infer_flux4d.py      # 推理与导出
├── tools/
│   └── vis/                 # 投影/深度/光流/速度可视化
├── tests/                   # 关键模块单测（后续补齐）
├── docs/                    # 文档与实验记录
├── assets/                  # 图表与可视化产物（可选）
└── third_party/             # 外部依赖仓库（如 gsplat/3DGS）
```

## 模块：配置（configs/）

- 文件：`configs/flux4d_base.yaml`
  - 字段：dataset/model/render/loss/train/eval
- 文件：`configs/flux4d_full.yaml`
  - 字段：继承 base，设置 full 训练迭代与调度
- 文件：`configs/flux4d_debug.yaml`
  - 字段：保持论文视图数与分辨率，缩小 batch 与迭代数

## 模块：数据索引与缓存（data/）

- 文件：`data/metadata/pandaset_full_clips.pkl`
  - 字段：clip_id/timestamps/intrinsics/extrinsics/image_paths/lidar_paths
- 文件：`data/metadata/pandaset_tiny_clips.pkl`
  - 字段：与 full 一致，记录调试片段
- 目录：`data/cache/lift/`
  - 内容：G_init/尺度/投影缓存（可选）

## 模块：数据与索引（PandaSet）

- 文件：`src/flux4d/datasets/pandaset_clips.py`
  - 函数：`build_pandaset_clip_index(data_root, out_pkl_full, out_pkl_tiny, clip_len_s, stride)`
  - 函数：`load_clip(meta_entry) -> ClipData`
  - 函数：`sample_views_for_train(clip, num_views, strategy) -> ViewBatch`

## 模块：LiDAR → 高斯（Lift）

- 文件：`src/flux4d/lift/lift_lidar.py`
  - 函数：`voxel_downsample_points(points, voxel_size) -> points_ds`
  - 函数：`compute_knn_mean_distance(points, k) -> scale`
  - 函数：`project_points_to_cameras(points, intrinsics, extrinsics) -> uv_depth`
  - 函数：`sample_colors(images, uv) -> colors`
  - 函数：`create_gaussians_from_lidar(points, colors, scales, t_i) -> Gaussians`
  - 函数：`add_sky_and_far_points(gaussians, radius, num_points) -> Gaussians`
  - 函数：`build_initial_gaussians_for_clip(clip) -> G_init`

## 模块：核心模型（Flux4D-base/Flux4D）

- 文件：`src/flux4d/storm/gaussian_voxelizer.py`
  - 函数：`voxelize_gaussians(gaussians, voxel_size) -> SparseTensor`
  - 函数：`build_voxel_features(gaussians) -> features`
- 文件：`src/flux4d/storm/flux4d_unet.py`
  - 函数：`build_sparse_unet(cfg) -> model`
  - 函数：`forward(voxel_tensor, gaussians) -> (gaussians_refined, velocities, aux)`
- 文件：`src/flux4d/storm/iterative_refine.py`
  - 函数：`compute_gaussian_gradients(render_outputs, targets) -> grad_tensor`
  - 函数：`refine_step(gaussians, gradients) -> gaussians_refined`
  - 函数：`iterative_refine(gaussians, gradients, num_iters) -> gaussians_final`
- 文件：`src/flux4d/storm/flux4d_model.py`
  - 函数：`forward(G_init, T, refine_iters) -> (G, V, aux)`

## 模块：时间推进与渲染

- 文件：`src/flux4d/render/flux4d_renderer.py`
  - 函数：`apply_linear_motion(gaussians, velocities, t_target) -> gaussians_t`
  - 函数：`apply_polynomial_motion(gaussians, motion_params, t_target) -> gaussians_t`
  - 函数：`render_rgb_depth(gaussians, camera) -> (rgb, depth)`
  - 函数：`render_flow_map(gaussians, velocities, camera, t_src, t_tgt) -> flow`

## 模块：损失与动态重加权

- 文件：`src/flux4d/losses/flux4d_losses.py`
  - 函数：`photometric_l1_loss(pred, target, weight_map=None) -> loss`
  - 函数：`ssim_loss(pred, target, weight_map=None) -> loss`
  - 函数：`depth_l1_loss(depth_pred, lidar_proj_depth) -> loss`
  - 函数：`velocity_regularization(velocities) -> loss`
  - 函数：`build_dynamic_weight_map_from_flow(flow, alpha, clip) -> weight_map`
  - 函数：`total_loss(...) -> loss_dict`

## 模块：指标（Metrics）

- 文件：`src/flux4d/metrics/metrics.py`
  - 函数：`compute_psnr(rgb_pred, rgb_gt) -> float`
  - 函数：`compute_ssim(rgb_pred, rgb_gt) -> float`
  - 函数：`compute_depth_rmse(depth_pred, depth_gt) -> float`
  - 函数：`compute_flow_epe(flow_pred, flow_gt) -> float`

## 模块：训练与评测引擎

- 文件：`src/flux4d/engine/trainer.py`
  - 函数：`train_loop(cfg) -> None`
  - 函数：`eval_loop(cfg) -> metrics`
  - 函数：`save_debug_renders(batch, outputs, out_dir)`
- 文件：`src/flux4d/engine/checkpoint.py`
  - 函数：`save_ckpt(state, out_path) -> None`
  - 函数：`load_ckpt(path, map_location) -> state`

## 模块：通用工具

- 文件：`src/flux4d/utils/config.py`
  - 函数：`load_config(path) -> Cfg`
  - 函数：`merge_overrides(cfg, overrides) -> Cfg`
- 文件：`src/flux4d/utils/geometry.py`
  - 函数：`compose_extrinsics(R, t) -> T`
  - 函数：`transform_points(points, T) -> points_t`

## 模块：脚本入口

- 文件：`scripts/preprocess_flux4d.py`
  - 函数：`main() -> None`
- 文件：`scripts/train_flux4d.py`
  - 函数：`main() -> None`
- 文件：`scripts/infer_flux4d.py`
  - 函数：`main() -> None`

## 模块：可视化工具

- 文件：`tools/vis/vis_lift.py`
  - 函数：`main() -> None`
- 文件：`tools/vis/vis_flow.py`
  - 函数：`main() -> None`
- 文件：`tools/vis/make_video.py`
  - 函数：`main() -> None`

## 模块：测试

- 文件：`tests/test_lift.py`
  - 函数：`test_voxel_downsample() -> None`
  - 函数：`test_knn_mean_distance() -> None`
- 文件：`tests/test_render.py`
  - 函数：`test_render_shapes() -> None`

## 模块：资源与第三方

- 目录：`assets/`
  - 内容：可视化图表与视频产物
- 目录：`third_party/`
  - 内容：gsplat/3DGS 等外部依赖（按需引入）

# 验证与可视化策略

## 阶段验证门禁

- 阶段0：GaussianSTORM demo 渲染正确；PandaSet 数据可读。
- 阶段2：G_init 渲染与原图结构一致；深度与投影 LiDAR 对齐。
- 阶段3：tiny clip 过拟合成功（PSNR/SSIM 上升，速度分布稳定）。
- 阶段4：插值帧稳定；Flow 可视化方向与相邻帧位移一致。
- 阶段5：迭代 refinement 提升纹理细节；动态区域误差下降。

## 4D 动态场景可视化

- 渲染 t0..tN 的 RGB/Depth/Flow 序列并合成视频。
- 生成新视角轨迹视频，检查时空一致性与遮挡处理。
- 对动态主体做局部放大对比：迭代前后、动态权重前后。

## tiny 数据集快速验证

- 选 1–2 个短片段，固定视图数训练到过拟合。
- 监控重建 loss、速度范数、渲染差分图。
- 若无法过拟合，优先排查时间同步、坐标系与渲染链路。

# 风险与优先级

## 风险清单（按优先级）

- P0 数据对齐错误（时间戳/外参错位）
  - 对策：帧级可视化对齐检查，叠加点云到图像验证。
- P0 显存不足（24G 调试批量过大）
  - 对策：减小 batch、梯度累积、混合精度、激活检查点。
- P0 渲染/损失实现偏差
  - 对策：先复现 Flux4D-base，固定权重逐项对齐损失。
- P1 LiDAR 稀疏导致外观欠拟合
  - 对策：多帧聚合、随机点/单目深度辅助。
- P1 动态重加权不稳定
  - 对策：权重裁剪与平滑；先在 tiny 上验证稳定性。
- P1 速度预测退化或发散
  - 对策：监控 v_i 分布，调节 λ_vel 与学习率。
- P2 迭代优化引入伪影
  - 对策：限制迭代次数与梯度幅度，保留 baseline 对比。
- P2 运动模型过简（线性假设不足）
  - 对策：启用多项式运动并做消融验证。
- P2 评测指标难复现
  - 对策：严格按论文评测协议采样，并保留可视化趋势证据。
- P3 工程复杂度过高
  - 对策：优先最小可跑通版本，逐步叠加增强模块。
